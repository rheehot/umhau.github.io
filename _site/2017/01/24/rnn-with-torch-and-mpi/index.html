<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">


    <link rel="stylesheet" type="text/css" href="/assets/css/styles.css">
    <meta name="viewport" content="width=device-width">
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
    <script src="/js/infinite-jekyll.js"></script>

  </head>
  <body>
    <box class="wrapper">
      <header>
        <a href="http://localhost:4000"> <h1>*nixing around</h1> </a>
        <p>A programmer's journal of complicated projects.</p>
        <p class="view"><a href="">github</a> | <a href="http://localhost:4000/about">about</a> | <a href="http://localhost:4000/explore">explore</a></p>

        <p>testing</p>

      </header>
      <section>

      <div class="post">

    <header class="post-header">
        
    <h1 class="post-title">RNN with Torch and MPI</h1>
    <p 
        class="post-meta">Jan 24, 2017 • <a  href="/2017/01/24/rnn-with-torch-and-mpi/">permalink</a>
        <i>  • distributed computing • DATA • Ubuntu Server 16.04.1 LTS • torch • word-rnn • MPI</i> 
    </p>
    </header>

    <article class="post-content">
    This is being installed on machines running Ubuntu Server 16.04.1 LTS. &nbsp;Does not work on Linux Mint (the torch install script doesn't detect that OS).<br /><br />Most of the following installations have to be performed on each computer. &nbsp;I didn't re-download everything, since it was going to be put in the same place, but I did cd in and re-run the installation procedure. &nbsp;That ensured the necessary files were added to all the right places elsewhere in the system. <br /><br />Here, I'm <b>walking through the process of running Torch on a cluster.</b> &nbsp;CPUs, not GPUs. &nbsp;The performance benefit comes from the slave nodes being allowed greater latitude in searching for local optima to 'solve' the neural net. &nbsp;Every so often, they 'touch base' with the master node and synchronize the result of their computations. &nbsp;Read the abstract of&nbsp;<a href="https://cs.nyu.edu/~zsx/nips2015.pdf" target="_blank">Sixin Zhang's paper</a> to get a more detailed idea of what's happening. &nbsp;As far as the implementation goes, "<b>the idea is to transform the torch data structure (tensor, table etc) into a storage (contiguous in memory) and then send/recv [sic] it</b>." <a href="https://github.com/sixin-zh/mpiT/issues/1#issuecomment-71393728" target="_blank">src</a>.<br /><h3>Background Sources</h3>Keep track of where I found the info I used to figure this out.<br /><br /><a href="https://bbs.archlinux.org/viewtopic.php?id=159999">https://bbs.archlinux.org/viewtopic.php?id=159999</a><br /><a href="http://torch.ch/docs/getting-started.html">http://torch.ch/docs/getting-started.html</a><br /><a href="https://groups.google.com/forum/#!topic/torch7/Xs814a5_xgI">https://groups.google.com/forum/#!topic/torch7/Xs814a5_xgI</a><br /><h3>Set up MPI (beowulf cluster)</h3><div>Follow the instructions in these two posts first. &nbsp;They get you to the point of a working cluster, starting from a collection of unused PCs and the relevant hardware.<br /><br /></div><a href="https://nixingaround.blogspot.com/2017/01/a-homebrew-beowulf-cluster-part-1.html">https://nixingaround.blogspot.com/2017/01/a-homebrew-beowulf-cluster-part-1.html</a><br /><a href="https://nixingaround.blogspot.com/2017/01/a-homemade-beowulf-cluster-part-2.html">https://nixingaround.blogspot.com/2017/01/a-homemade-beowulf-cluster-part-2.html</a><br /><h3>prevent SSH from losing connection</h3><div>I had some trouble here, where I was trying to use ssh over the same wires that were providing MPI communication in the cluster. &nbsp;I kept losing connection after initializing the computations. &nbsp;It may not be necessary, so I wouldn't do this unless you run into trouble of that sort. &nbsp;</div><div><br /></div><a href="https://nixingaround.blogspot.com/2017/01/internet-via-ethernet-ssh-via-wireless.html">https://nixingaround.blogspot.com/2017/01/internet-via-ethernet-ssh-via-wireless.html</a><br /><br />Ok, that's not an optimal solution. Better to initialize a virtual terminal and run the computations in that. &nbsp;When the connection is inevitably dropped, just recover that terminal.<br /><br /><a href="http://unix.stackexchange.com/questions/22781/how-to-recover-a-shell-after-a-disconnection">http://unix.stackexchange.com/questions/22781/how-to-recover-a-shell-after-a-disconnection</a><br /><h3>Install Torch</h3><i><b>Note: </b>it may be useful to install the <a href="https://software.intel.com/en-us/intel-mkl" target="_blank">MKL library</a> ahead of torch. &nbsp;It accelerates the math routines that I assume will be present in the computations I'm going to perform. &nbsp;</i><br /><br />This provides dependencies needed to install the mpiT package that lets Torch7 work with MPI. &nbsp;Start in the breca home directory. &nbsp;<b>On the master node</b>, run the following. <br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">cd<br />git clone https://github.com/torch/distro.git ~/torch --recursive</span></span></pre>Then, on <b>all nodes </b>(master and slave), run the following from the breca account:<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">cd ~/torch; bash install-deps<br />./install.sh</span></span></pre><i>[I'm not sure, but I think MPICH has to be reinstalled after GCC 4.x is installed with the dependencies. &nbsp;Leaving this note here in case of future problems.]</i><br /><br />After the install script finished running, it told me that it had not updated my shell profile. &nbsp;So, we're adding a line to the ~/.profile script. &nbsp;(we're using that, and not the bashrc file, because when logging on to the breca account bash isn't automatically run. &nbsp;If I ever forget and try to use Torch without bash, I could run into problems this can avoid.)<br /><br />Do the following on <b>all nodes</b>:<br /><pre style="background-color: #eff0f1; border: 0px; color: #333333; font-size: 14px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;">echo ". /mirror/breca/torch/install/bin/torch-activate" | sudo tee -a /mirror/breca/.profile</pre>Now re-run the file, so the code you added is executed.<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">source ~/.profile</span></span></pre>Installing this way allows you to only download the package once, but use it to install the software to all nodes in the cluster. &nbsp;(and as a side note, the install-deps script doesn't detect Linux Mint - it's one of the reasons this walk-through is using Ubuntu Server)<br /><br />Test that Torch has been installed:<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">th</span></span></pre>Close the program<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">exit</span></span></pre><h3>MPI compatibility with Torch</h3>Source:&nbsp;<a href="https://github.com/sixin-zh/mpiT">https://github.com/sixin-zh/mpiT</a><br /><br /><b>Do this on the master node.</b>&nbsp;You'll be able to access the downloaded files from all the nodes - they're going in the /mirror directory.&nbsp;Download from github and install.<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">cd ~/<br />mkdir -p tools &amp;&amp; cd tools<br />git clone https://github.com/sixin-zh/mpiT<br />cd</span></span></pre>Now Do the rest of the steps <b>on all the nodes</b>, master and slave.<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">cd <br />cd tools/mpiT</span></span></pre>By default, MPI_PREFIX should be set to /usr. &nbsp;See&nbsp;<a href="https://github.com/sixin-zh/mpiT/issues/23#issuecomment-265338469" target="_blank">link</a>.<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">export MPI_PREFIX="/usr"<br />echo "export MPI_PREFIX='/usr'" &gt;&gt; ~/.profile</span></span></pre>Since I'm working with MPICH rather than OpenMPI (see cluster installation notes above),<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">luarocks make mpit-mvapich-1.rockspec</span></span></pre><h4>Tests</h4><div>First, <b>figure out how many processors you have.</b> &nbsp;You did already; that's the sum of the numbers in your machinefile in the /mirror directory. &nbsp;We'll say you have 12 cores. &nbsp;Since our counting starts at 0, tell the computer you have 11. &nbsp;Adjust according to your actual situation.&nbsp;</div><div><br /></div><div>Next, use a bunch of terminals and log into each of your nodes simultaneously. &nbsp;Install:</div><div><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">sudo apt-get install htop </span></span></pre></div><div>And run<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">htop</span></span></pre>on each machine and watch the CPU usage as you perform the following tests. &nbsp;If only the master node shows activity, you have a problem. &nbsp;</div><div><br /></div><div>Create ./data/torch7 in the home directory, and then download the test data to that location. &nbsp;Ensure you're logged in as the MPI user.</div><div><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">mkdir -p ~/data/torch7/mnist10/ &amp;&amp; cd ~/data/torch7/mnist10<br />wget http://cs.nyu.edu/~zsx/mnist10/train_32x32.th7<br />wget http://cs.nyu.edu/~zsx/mnist10/test_32x32.th7<br />cd ~/tools/mpiT</span></span></pre></div><div>Now run the tests. Sanity check: did mpiT install successfully?<b>&nbsp;<i>Note: </i></b><i>I ran into an 'error 75' at this point, and the solution was to explicitly define the location of the files involved starting from the root directory.&nbsp;</i><br /><pre style="background-color: #eff0f1; border: 0px; color: #333333; font-size: 14px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;">mpirun -np 11 /mirror/machinefile th /mirror/breca/tools/mpiT/test.lua</pre>Check that the MPI integration is working. &nbsp;Move down to the folder with the asynchronous algorithms.<br /><pre style="background-color: #eff0f1; border: 0px; color: #333333; font-size: 14px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;">cd asyncsgd</pre>I think this test only needs to run on the master node - as long as you've installed everything to all the nodes (as appropriate), it doesn't need to be run everywhere. &nbsp;I think it's just checking that Torch is successfully configured to run on a CPU.<br /><pre style="background-color: #eff0f1; border: 0px; color: #333333; font-size: 14px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;">th claunch.lua</pre>Test bandwidth: I have no idea what this does, but it fails if the requested number of processors is odd. &nbsp;I'm sticking with the default of 4 processors, which (I'm guessing) is the number on a single node. &nbsp;As long as it works...? &nbsp;It seems to be checking the bandwidth through the cluster. &nbsp;<a href="https://github.com/sixin-zh/mpiT/issues/1#issuecomment-69132482" target="_blank">There isn't a whole lot of documentation.</a><br /><pre style="background-color: #eff0f1; border: 0px; color: #333333; font-size: 14px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;">mpirun -np 4 -f ../../../../machinefile th ptest.lua </pre>Try parallel mnist training - this is the one that should tell you what's up. &nbsp;AFAIK, you'll probably end up using a variant of this code to run whatever analysis you have planned. &nbsp;If you look inside, you'll notice that what you're running is some kind of abstraction - the algorithm (such as it is for a test run) seems to be implemented in goot.lua. &nbsp;In fact, this is a 'real-world' test of sorts - <a href="https://en.wikipedia.org/wiki/MNIST_database" target="_blank">the MNIST data set</a> is the handwritten character collection researchers like to use for testing their models. <br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="font-size: 14px;">mpirun -np 11 -f ../../../../machinefile th mlaunch.lua</span></span></pre></div>and this is as far as I've actually made it without errors (up to this point, barring abnormalities in the PCs used, everything works perfectly for me).<br /><h3>Install Word RNN</h3>Clone the software from github.<br /><pre style="background-color: #eff0f1; border: 0px; color: #333333; font-size: 14px; margin-bottom: 1em; overflow: auto; padding: 5px; text-align: justify; width: auto; word-wrap: normal;">mkdir ~/projects<br />cd projects<br />git clone https://github.com/larspars/word-rnn.git</pre>That's actually all there is to it. &nbsp;Now cd into the word-rnn directory to run the test stuff. &nbsp;Before the tests and tools, though, there's a fix that you have to perform.
    </article>

    <p class="extra-space"></p>
    <hr>
    <p class="extra-space"></p>

</div>





      </section>
      <footer>
        <p><small>Hosted on GitHub &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a> and <a href="https://github.com/umhau">umhau</a></small></p>
      </footer>
    </box>
    <script src="/assets/js/scale.fix.js"></script>


  



  </body>
</html>
