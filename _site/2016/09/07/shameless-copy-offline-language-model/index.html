<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">

<!-- Begin Jekyll SEO tag v2.3.0 -->
<title>[shameless copy] Offline Language Model Creation for PocketSphinx | nixing around</title>
<meta property="og:title" content="[shameless copy] Offline Language Model Creation for PocketSphinx" />
<meta name="author" content="umhau" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Normally, I&#39;d be writing these myself. &nbsp;But this time, the explanation was so unusually good that I don&#39;t feel the need to simplify it. &nbsp;It&#39;s fantastic for my purposes as-is. &nbsp;Source. &nbsp;The purpose here is to create the statistical language model that pocketsphinx uses to convert phonetics into words. &nbsp;The model is based entirely on what type of sentences it expects to encounter, as defined by the input reference text. &nbsp;I need this running as a self-contained script in order to make language model generation a seamless part of my project. &nbsp;All the user should have to do is provide a ready-made reference text, and the script should generate the rest. &nbsp; ARPA model training with CMUCLMTK You need to download and install cmuclmtk. See&nbsp;CMU Sphinx Downloads&nbsp;for details.The process for creating a language model is as follows:1) Prepare a reference text that will be used to generate the language model. The language model toolkit expects its input to be in the form of normalized text files, with utterances delimited by&nbsp;&lt;s&gt;&nbsp;and&nbsp;&lt;/s&gt;&nbsp;tags. A number of input filters are available for specific corpora such as Switchboard, ISL and NIST meetings, and HUB5 transcripts. The result should be the set of sentences that are bounded by the start and end sentence markers: &lt;s&gt; and &lt;/s&gt;. Here&#39;s an example:&lt;s&gt; generally cloudy today with scattered outbreaks of rain and drizzle persistent and heavy at times &lt;/s&gt;&lt;s&gt; some dry intervals also with hazy sunshine especially in eastern parts in the morning &lt;/s&gt;&lt;s&gt; highest temperatures nine to thirteen Celsius in a light or moderate mainly east south east breeze &lt;/s&gt;&lt;s&gt; cloudy damp and misty today with spells of rain and drizzle in most places much of this rain will be light and patchy but heavier rain may develop in the west later &lt;/s&gt;More data will generate better language models. The&nbsp;weather.txt&nbsp;file from sphinx4 (used to generate the weather language model) contains nearly 100,000 sentences.2) Generate the vocabulary file. This is a list of all the words in the file: text2wfreq &lt; weather.txt | wfreq2vocab &gt; weather.tmp.vocab3) You may want to edit the vocabulary file to remove words (numbers, misspellings, names). If you find misspellings, it is a good idea to fix them in the input transcript.4) If you want a closed vocabulary language model (a language model that has no provisions for unknown words), then you should remove sentences from your input transcript that contain words that are not in your vocabulary file.5) Generate the arpa format language model with the commands:% text2idngram -vocab weather.vocab -idngram weather.idngram &lt; weather.closed.txt% idngram2lm -vocab_type 0 -idngram weather.idngram -vocab \ weather.vocab -arpa weather.lm6) Generate the CMU binary form (BIN)sphinx_lm_convert -i weather.lm -o weather.lm.binThe CMUCLTK tools and commands are documented at&nbsp;The CMU-Cambridge Language Modeling Toolkit page." />
<meta property="og:description" content="Normally, I&#39;d be writing these myself. &nbsp;But this time, the explanation was so unusually good that I don&#39;t feel the need to simplify it. &nbsp;It&#39;s fantastic for my purposes as-is. &nbsp;Source. &nbsp;The purpose here is to create the statistical language model that pocketsphinx uses to convert phonetics into words. &nbsp;The model is based entirely on what type of sentences it expects to encounter, as defined by the input reference text. &nbsp;I need this running as a self-contained script in order to make language model generation a seamless part of my project. &nbsp;All the user should have to do is provide a ready-made reference text, and the script should generate the rest. &nbsp; ARPA model training with CMUCLMTK You need to download and install cmuclmtk. See&nbsp;CMU Sphinx Downloads&nbsp;for details.The process for creating a language model is as follows:1) Prepare a reference text that will be used to generate the language model. The language model toolkit expects its input to be in the form of normalized text files, with utterances delimited by&nbsp;&lt;s&gt;&nbsp;and&nbsp;&lt;/s&gt;&nbsp;tags. A number of input filters are available for specific corpora such as Switchboard, ISL and NIST meetings, and HUB5 transcripts. The result should be the set of sentences that are bounded by the start and end sentence markers: &lt;s&gt; and &lt;/s&gt;. Here&#39;s an example:&lt;s&gt; generally cloudy today with scattered outbreaks of rain and drizzle persistent and heavy at times &lt;/s&gt;&lt;s&gt; some dry intervals also with hazy sunshine especially in eastern parts in the morning &lt;/s&gt;&lt;s&gt; highest temperatures nine to thirteen Celsius in a light or moderate mainly east south east breeze &lt;/s&gt;&lt;s&gt; cloudy damp and misty today with spells of rain and drizzle in most places much of this rain will be light and patchy but heavier rain may develop in the west later &lt;/s&gt;More data will generate better language models. The&nbsp;weather.txt&nbsp;file from sphinx4 (used to generate the weather language model) contains nearly 100,000 sentences.2) Generate the vocabulary file. This is a list of all the words in the file: text2wfreq &lt; weather.txt | wfreq2vocab &gt; weather.tmp.vocab3) You may want to edit the vocabulary file to remove words (numbers, misspellings, names). If you find misspellings, it is a good idea to fix them in the input transcript.4) If you want a closed vocabulary language model (a language model that has no provisions for unknown words), then you should remove sentences from your input transcript that contain words that are not in your vocabulary file.5) Generate the arpa format language model with the commands:% text2idngram -vocab weather.vocab -idngram weather.idngram &lt; weather.closed.txt% idngram2lm -vocab_type 0 -idngram weather.idngram -vocab \ weather.vocab -arpa weather.lm6) Generate the CMU binary form (BIN)sphinx_lm_convert -i weather.lm -o weather.lm.binThe CMUCLTK tools and commands are documented at&nbsp;The CMU-Cambridge Language Modeling Toolkit page." />
<link rel="canonical" href="http://localhost:4000/2016/09/07/shameless-copy-offline-language-model/" />
<meta property="og:url" content="http://localhost:4000/2016/09/07/shameless-copy-offline-language-model/" />
<meta property="og:site_name" content="nixing around" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2016-09-07T09:45:00-04:00" />
<script type="application/ld+json">
{"name":null,"description":"Normally, I&#39;d be writing these myself. &nbsp;But this time, the explanation was so unusually good that I don&#39;t feel the need to simplify it. &nbsp;It&#39;s fantastic for my purposes as-is. &nbsp;Source. &nbsp;The purpose here is to create the statistical language model that pocketsphinx uses to convert phonetics into words. &nbsp;The model is based entirely on what type of sentences it expects to encounter, as defined by the input reference text. &nbsp;I need this running as a self-contained script in order to make language model generation a seamless part of my project. &nbsp;All the user should have to do is provide a ready-made reference text, and the script should generate the rest. &nbsp; ARPA model training with CMUCLMTK You need to download and install cmuclmtk. See&nbsp;CMU Sphinx Downloads&nbsp;for details.The process for creating a language model is as follows:1) Prepare a reference text that will be used to generate the language model. The language model toolkit expects its input to be in the form of normalized text files, with utterances delimited by&nbsp;&lt;s&gt;&nbsp;and&nbsp;&lt;/s&gt;&nbsp;tags. A number of input filters are available for specific corpora such as Switchboard, ISL and NIST meetings, and HUB5 transcripts. The result should be the set of sentences that are bounded by the start and end sentence markers: &lt;s&gt; and &lt;/s&gt;. Here&#39;s an example:&lt;s&gt; generally cloudy today with scattered outbreaks of rain and drizzle persistent and heavy at times &lt;/s&gt;&lt;s&gt; some dry intervals also with hazy sunshine especially in eastern parts in the morning &lt;/s&gt;&lt;s&gt; highest temperatures nine to thirteen Celsius in a light or moderate mainly east south east breeze &lt;/s&gt;&lt;s&gt; cloudy damp and misty today with spells of rain and drizzle in most places much of this rain will be light and patchy but heavier rain may develop in the west later &lt;/s&gt;More data will generate better language models. The&nbsp;weather.txt&nbsp;file from sphinx4 (used to generate the weather language model) contains nearly 100,000 sentences.2) Generate the vocabulary file. This is a list of all the words in the file: text2wfreq &lt; weather.txt | wfreq2vocab &gt; weather.tmp.vocab3) You may want to edit the vocabulary file to remove words (numbers, misspellings, names). If you find misspellings, it is a good idea to fix them in the input transcript.4) If you want a closed vocabulary language model (a language model that has no provisions for unknown words), then you should remove sentences from your input transcript that contain words that are not in your vocabulary file.5) Generate the arpa format language model with the commands:% text2idngram -vocab weather.vocab -idngram weather.idngram &lt; weather.closed.txt% idngram2lm -vocab_type 0 -idngram weather.idngram -vocab \\ weather.vocab -arpa weather.lm6) Generate the CMU binary form (BIN)sphinx_lm_convert -i weather.lm -o weather.lm.binThe CMUCLTK tools and commands are documented at&nbsp;The CMU-Cambridge Language Modeling Toolkit page.","author":{"@type":"Person","name":"umhau"},"@type":"BlogPosting","url":"http://localhost:4000/2016/09/07/shameless-copy-offline-language-model/","publisher":null,"image":null,"headline":"[shameless copy] Offline Language Model Creation for PocketSphinx","dateModified":"2016-09-07T09:45:00-04:00","datePublished":"2016-09-07T09:45:00-04:00","sameAs":null,"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2016/09/07/shameless-copy-offline-language-model/"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" type="text/css" href="/assets/css/styles.css">
    <meta name="viewport" content="width=device-width">
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
    <script src="/js/infinite-jekyll.js"></script>

  </head>
  <body>
    <box class="wrapper">
      <header>
        <a href="http://localhost:4000"> <h1>*nixing around</h1> </a>
        <p>A programmer's journal of complicated projects.</p>
        <p class="view"><a href="">github</a> | <a href="http://localhost:4000/about">about</a> | <a href="http://localhost:4000/explore">explore</a></p>

        <p>testing</p>

      </header>
      <section>

      <div class="post">

    <header class="post-header">
        
    <h1 class="post-title">[shameless copy] Offline Language Model Creation for PocketSphinx</h1>
    <p 
        class="post-meta">Sep 7, 2016 • <a  href="/2016/09/07/shameless-copy-offline-language-model/">permalink</a>
        <i>  • speech to text • Language Model • CMU Sphinx</i> 
    </p>
    </header>

    <article class="post-content">
    <div style="clear: left; color: #333333; line-height: 1.2; margin: 0px 0px 0.888em; padding: 0px;"><span style="font-family: inherit;">Normally, I'd be writing these myself. &nbsp;But this time, the explanation was so unusually good that I don't feel the need to simplify it. &nbsp;It's fantastic for my purposes as-is. &nbsp;<a href="http://cmusphinx.sourceforge.net/wiki/tutoriallm#arpa_model_training_with_cmuclmtk" target="_blank">Source</a>. &nbsp;</span><br /><span style="line-height: 1.2;"><br /></span><span style="line-height: 1.2;">The purpose here is to create the statistical language model that pocketsphinx uses to convert phonetics into words. &nbsp;The model is based entirely on what type of sentences it expects to encounter, as defined by the input reference text. &nbsp;</span><br /><span style="line-height: 1.2;"><br /></span><span style="line-height: 1.2;">I need this running as a self-contained script in order to make language model generation a seamless part of my project. &nbsp;All the user should have to do is provide a ready-made reference text, and the script should generate the rest. &nbsp;</span></div><h3 class="sectionedit10" id="arpa_model_training_with_cmuclmtk" style="clear: left; color: #333333; font-family: &quot;Lucida Grande&quot;, Verdana, Arial, sans-serif; font-size: 1.125em; line-height: 1.2; margin: 0px 0px 0.888em; padding: 0px;">ARPA model training with CMUCLMTK</h3><div class="level3" style="color: #333333; font-family: &quot;Lucida Grande&quot;, Verdana, Arial, sans-serif; font-size: 14px; margin: 0px; padding: 0px;"><div style="line-height: 1.4em; margin-bottom: 1.4em; padding: 0px;">You need to download and install cmuclmtk. See&nbsp;<a class="wikilink1" href="http://cmusphinx.sourceforge.net/wiki/download" style="color: #437f62; outline: none; text-decoration: none;" title="download">CMU Sphinx Downloads</a>&nbsp;for details.</div><div style="line-height: 1.4em; margin-bottom: 1.4em; padding: 0px;">The process for creating a language model is as follows:</div><div style="line-height: 1.4em; margin-bottom: 1.4em; padding: 0px;">1) Prepare a reference text that will be used to generate the language model. The language model toolkit expects its input to be in the form of normalized text files, with utterances delimited by&nbsp;<code style="background-color: white; border-radius: 2px; box-shadow: rgb(204, 204, 204) 0px 0px 0.3em inset; direction: ltr; font-family: Consolas, &quot;Andale Mono WT&quot;, &quot;Andale Mono&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Nimbus Mono L&quot;, Monaco, &quot;Courier New&quot;, monospace; font-size: 1em;">&lt;s&gt;</code>&nbsp;and&nbsp;<code style="background-color: white; border-radius: 2px; box-shadow: rgb(204, 204, 204) 0px 0px 0.3em inset; direction: ltr; font-family: Consolas, &quot;Andale Mono WT&quot;, &quot;Andale Mono&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Nimbus Mono L&quot;, Monaco, &quot;Courier New&quot;, monospace; font-size: 1em;">&lt;/s&gt;</code>&nbsp;tags. A number of input filters are available for specific corpora such as Switchboard, ISL and NIST meetings, and HUB5 transcripts. The result should be the set of sentences that are bounded by the start and end sentence markers: &lt;s&gt; and &lt;/s&gt;. Here's an example:</div><pre class="code" style="background-color: white; border-radius: 2px; border: 1px solid rgb(204, 204, 204); box-shadow: rgb(204, 204, 204) 0px 0px 0.5em inset; direction: ltr; font-family: Consolas, &quot;Andale Mono WT&quot;, &quot;Andale Mono&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Nimbus Mono L&quot;, Monaco, &quot;Courier New&quot;, monospace; font-size: 1em; line-height: 1.4em; margin-bottom: 1.4em; overflow: auto; padding: 0.7em 1em; word-wrap: normal;">&lt;s&gt; generally cloudy today with scattered outbreaks of rain and drizzle persistent and heavy at times &lt;/s&gt;<br />&lt;s&gt; some dry intervals also with hazy sunshine especially in eastern parts in the morning &lt;/s&gt;<br />&lt;s&gt; highest temperatures nine to thirteen Celsius in a light or moderate mainly east south east breeze &lt;/s&gt;<br />&lt;s&gt; cloudy damp and misty today with spells of rain and drizzle in most places much of this rain will be <br />light and patchy but heavier rain may develop in the west later &lt;/s&gt;</pre><div style="line-height: 1.4em; margin-bottom: 1.4em; padding: 0px;">More data will generate better language models. The&nbsp;<code style="background-color: white; border-radius: 2px; box-shadow: rgb(204, 204, 204) 0px 0px 0.3em inset; direction: ltr; font-family: Consolas, &quot;Andale Mono WT&quot;, &quot;Andale Mono&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Nimbus Mono L&quot;, Monaco, &quot;Courier New&quot;, monospace; font-size: 1em;">weather.txt</code>&nbsp;file from sphinx4 (used to generate the weather language model) contains nearly 100,000 sentences.</div><div style="line-height: 1.4em; margin-bottom: 1.4em; padding: 0px;">2) Generate the vocabulary file. This is a list of all the words in the file:</div><pre class="code" style="background-color: white; border-radius: 2px; border: 1px solid rgb(204, 204, 204); box-shadow: rgb(204, 204, 204) 0px 0px 0.5em inset; direction: ltr; font-family: Consolas, &quot;Andale Mono WT&quot;, &quot;Andale Mono&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Nimbus Mono L&quot;, Monaco, &quot;Courier New&quot;, monospace; font-size: 1em; line-height: 1.4em; margin-bottom: 1.4em; overflow: auto; padding: 0.7em 1em; word-wrap: normal;">    text2wfreq &lt; weather.txt | wfreq2vocab &gt; weather.tmp.vocab</pre><div style="line-height: 1.4em; margin-bottom: 1.4em; padding: 0px;">3) You may want to edit the vocabulary file to remove words (numbers, misspellings, names). If you find misspellings, it is a good idea to fix them in the input transcript.</div><div style="line-height: 1.4em; margin-bottom: 1.4em; padding: 0px;">4) If you want a closed vocabulary language model (a language model that has no provisions for unknown words), then you should remove sentences from your input transcript that contain words that are not in your vocabulary file.</div><div style="line-height: 1.4em; margin-bottom: 1.4em; padding: 0px;">5) Generate the arpa format language model with the commands:</div><pre class="code" style="background-color: white; border-radius: 2px; border: 1px solid rgb(204, 204, 204); box-shadow: rgb(204, 204, 204) 0px 0px 0.5em inset; direction: ltr; font-family: Consolas, &quot;Andale Mono WT&quot;, &quot;Andale Mono&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Nimbus Mono L&quot;, Monaco, &quot;Courier New&quot;, monospace; font-size: 1em; line-height: 1.4em; margin-bottom: 1.4em; overflow: auto; padding: 0.7em 1em; word-wrap: normal;">% text2idngram -vocab weather.vocab -idngram weather.idngram &lt; weather.closed.txt<br />% idngram2lm -vocab_type 0 -idngram weather.idngram -vocab \<br />     weather.vocab -arpa weather.lm</pre><div style="line-height: 1.4em; margin-bottom: 1.4em; padding: 0px;">6) Generate the CMU binary form (BIN)</div><pre class="code" style="background-color: white; border-radius: 2px; border: 1px solid rgb(204, 204, 204); box-shadow: rgb(204, 204, 204) 0px 0px 0.5em inset; direction: ltr; font-family: Consolas, &quot;Andale Mono WT&quot;, &quot;Andale Mono&quot;, &quot;Bitstream Vera Sans Mono&quot;, &quot;Nimbus Mono L&quot;, Monaco, &quot;Courier New&quot;, monospace; font-size: 1em; line-height: 1.4em; margin-bottom: 1.4em; overflow: auto; padding: 0.7em 1em; word-wrap: normal;">sphinx_lm_convert -i weather.lm -o weather.lm.bin</pre><div style="line-height: 1.4em; margin-bottom: 1.4em; padding: 0px;">The CMUCLTK tools and commands are documented at&nbsp;<a class="urlextern" href="http://www.speech.cs.cmu.edu/SLM/toolkit_documentation.html" rel="nofollow" style="color: #437f62; outline: none; text-decoration: none;" title="http://www.speech.cs.cmu.edu/SLM/toolkit_documentation.html">The CMU-Cambridge Language Modeling Toolkit page</a>.</div></div>
    </article>

    <p class="extra-space"></p>
    <hr>
    <p class="extra-space"></p>

</div>





      </section>
      <footer>
        <p><small>Hosted on GitHub &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a> and <a href="https://github.com/umhau">umhau</a></small></p>
      </footer>
    </box>
    <script src="/assets/js/scale.fix.js"></script>


  



  </body>
</html>
