<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">

<!-- Begin Jekyll SEO tag v2.3.0 -->
<title>Using PocketSphinx within Python Code | nixing around</title>
<meta property="og:title" content="Using PocketSphinx within Python Code" />
<meta name="author" content="umhau" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Here’s the source for what I’ve been working on. Looks like my installation records will have to be updated to account for a different installation source, and maybe a different version of the source code.Ok, here’s the process so far.  Install sphinxbase and pocketsphinx from GitHub - this means using the bleeding-edge versions, rather than the tried-and true alpha5 versions that I talked about in previous posts.  This just seems to work better.  Once this is all figured out, I’ll go back and clean those up.&lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;cd ~/toolsgit clone https://github.com/cmusphinx/sphinxbase.gitcd ./sphinxbase./autogen.sh./configuremakemake checkmake installcd ~/toolsgit clone https://github.com/cmusphinx/pocketsphinx.gitcd ./pocketsphinx./autogen.sh./configuremake clean allmake checksudo make install&lt;/pre&gt;Now look inside the pocketsphinx directory:&lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;cd ~/tools/pocketsphinx/swig/python/test&lt;/pre&gt;There’s a whole bunch of test scripts that walk you through the implementation of pocketsphinx in python.  It’s basically done for you.  Check the one called kws-test.py – that’s the one that will wait to hear a keyword, run a command when it does, then resume listening.  Perfect!I’m going to assume that you’ve already created your own voice model based on the other posts in this blog, and that you’ve got a directory dedicated to command and control experiments. If that’s not true, then just mess with the script without moving it.  Just make a backup.  The only effective difference is that the detection will be less accurate; for the purposes of this tutorial, ignore the rest of the code down to where I’ve pasted my copy of the python script.  The only thing you should change has to do with reading from the microphone rather than an audio file; change the script to match what I’ve got here.  You’re done now.  The rest of this tutorial is for those who have already created their own voice model.  See others of my posts for how to do that.&lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;# Open file to read the data# stream = open(os.path.join(datadir, “test-file.wav”), “rb”)# Alternatively you can read from microphoneimport pyaudio p = pyaudio.PyAudio()stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)stream.start_stream()&lt;/pre&gt;Ok.  For the rest of us, let’s get back to messing with this script.  While still in the test directory,&lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;mkdir ~/tools/cc_excp ./kws_test.py ~/tools/cc_ex/kws_test.pycd ~/tools/cc_ex/gedit kws_test.py&lt;/pre&gt;There’s a few changes to make in the python script.  Make sure the model directory has been adjusted.  Also, the script by default is checking in a .raw audio file for the keyword: uncomment and comment the relevant lines so the script uses pyaudio to record from the microphone.  The full text of my version of the script is below. Note that the keyphrase it’s looking for is the word ‘and’.  Pretty simple, and very likely to have been covered a lot in the voice training.Note also that there’s a weird quirk in the detection - you have to speak quickly.  I tried for a long time making long, sonorous ‘aaaannnnddd’ noises at my microphone, and it didn’t pick up.  Finally gave a short, staccato ‘and’ - it detected me right away.  Did it five more times, and it picked me up each time.  I don’t see a way to get around that - I think it’s built into the buffer, so it won’t even hear the whole thing otherwise.  Or maybe I just said ‘and’ in the training really fast each time, though I don’t think that’s likely. &lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;#!/usr/bin/pythonimport sys, osfrom pocketsphinx.pocketsphinx import *from sphinxbase.sphinxbase import *modeldir = “~/tools/train-voice-data-pocketsphinx”# Create a decoder with certain modelconfig = Decoder.default_config()config.set_string(‘-hmm’, os.path.join(modeldir, ‘neo-en/en-us’))config.set_string(‘-dict’, os.path.join(modeldir, ‘neo-en/cmudict-en-us.dict’))config.set_string(‘-keyphrase’, ‘and’)config.set_float(‘-kws_threshold’, 1e+1)#config.set_string(‘-logfn’, ‘/dev/null’)# Open file to read the data# stream = open(os.path.join(datadir, “test-file.wav”), “rb”)# Alternatively you can read from microphoneimport pyaudio p = pyaudio.PyAudio()stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)stream.start_stream()# Process audio chunk by chunk. On keyphrase detected perform action and restart searchdecoder = Decoder(config)decoder.start_utt()while True: buf = stream.read(1024) if buf: decoder.process_raw(buf, False, False) else: break if decoder.hyp() != None: print ([(seg.word, seg.prob, seg.start_frame, seg.end_frame) for seg in decoder.seg()]) print (“Detected keyphrase, restarting search”) decoder.end_utt() decoder.start_utt()&lt;/pre&gt;&lt;div&gt;Anyway, that’s all.  If it doesn’t work, don’t blame me.  That’s as dead simple as I know how to make it.&lt;/div&gt;" />
<meta property="og:description" content="Here’s the source for what I’ve been working on. Looks like my installation records will have to be updated to account for a different installation source, and maybe a different version of the source code.Ok, here’s the process so far.  Install sphinxbase and pocketsphinx from GitHub - this means using the bleeding-edge versions, rather than the tried-and true alpha5 versions that I talked about in previous posts.  This just seems to work better.  Once this is all figured out, I’ll go back and clean those up.&lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;cd ~/toolsgit clone https://github.com/cmusphinx/sphinxbase.gitcd ./sphinxbase./autogen.sh./configuremakemake checkmake installcd ~/toolsgit clone https://github.com/cmusphinx/pocketsphinx.gitcd ./pocketsphinx./autogen.sh./configuremake clean allmake checksudo make install&lt;/pre&gt;Now look inside the pocketsphinx directory:&lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;cd ~/tools/pocketsphinx/swig/python/test&lt;/pre&gt;There’s a whole bunch of test scripts that walk you through the implementation of pocketsphinx in python.  It’s basically done for you.  Check the one called kws-test.py – that’s the one that will wait to hear a keyword, run a command when it does, then resume listening.  Perfect!I’m going to assume that you’ve already created your own voice model based on the other posts in this blog, and that you’ve got a directory dedicated to command and control experiments. If that’s not true, then just mess with the script without moving it.  Just make a backup.  The only effective difference is that the detection will be less accurate; for the purposes of this tutorial, ignore the rest of the code down to where I’ve pasted my copy of the python script.  The only thing you should change has to do with reading from the microphone rather than an audio file; change the script to match what I’ve got here.  You’re done now.  The rest of this tutorial is for those who have already created their own voice model.  See others of my posts for how to do that.&lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;# Open file to read the data# stream = open(os.path.join(datadir, “test-file.wav”), “rb”)# Alternatively you can read from microphoneimport pyaudio p = pyaudio.PyAudio()stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)stream.start_stream()&lt;/pre&gt;Ok.  For the rest of us, let’s get back to messing with this script.  While still in the test directory,&lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;mkdir ~/tools/cc_excp ./kws_test.py ~/tools/cc_ex/kws_test.pycd ~/tools/cc_ex/gedit kws_test.py&lt;/pre&gt;There’s a few changes to make in the python script.  Make sure the model directory has been adjusted.  Also, the script by default is checking in a .raw audio file for the keyword: uncomment and comment the relevant lines so the script uses pyaudio to record from the microphone.  The full text of my version of the script is below. Note that the keyphrase it’s looking for is the word ‘and’.  Pretty simple, and very likely to have been covered a lot in the voice training.Note also that there’s a weird quirk in the detection - you have to speak quickly.  I tried for a long time making long, sonorous ‘aaaannnnddd’ noises at my microphone, and it didn’t pick up.  Finally gave a short, staccato ‘and’ - it detected me right away.  Did it five more times, and it picked me up each time.  I don’t see a way to get around that - I think it’s built into the buffer, so it won’t even hear the whole thing otherwise.  Or maybe I just said ‘and’ in the training really fast each time, though I don’t think that’s likely. &lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;#!/usr/bin/pythonimport sys, osfrom pocketsphinx.pocketsphinx import *from sphinxbase.sphinxbase import *modeldir = “~/tools/train-voice-data-pocketsphinx”# Create a decoder with certain modelconfig = Decoder.default_config()config.set_string(‘-hmm’, os.path.join(modeldir, ‘neo-en/en-us’))config.set_string(‘-dict’, os.path.join(modeldir, ‘neo-en/cmudict-en-us.dict’))config.set_string(‘-keyphrase’, ‘and’)config.set_float(‘-kws_threshold’, 1e+1)#config.set_string(‘-logfn’, ‘/dev/null’)# Open file to read the data# stream = open(os.path.join(datadir, “test-file.wav”), “rb”)# Alternatively you can read from microphoneimport pyaudio p = pyaudio.PyAudio()stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)stream.start_stream()# Process audio chunk by chunk. On keyphrase detected perform action and restart searchdecoder = Decoder(config)decoder.start_utt()while True: buf = stream.read(1024) if buf: decoder.process_raw(buf, False, False) else: break if decoder.hyp() != None: print ([(seg.word, seg.prob, seg.start_frame, seg.end_frame) for seg in decoder.seg()]) print (“Detected keyphrase, restarting search”) decoder.end_utt() decoder.start_utt()&lt;/pre&gt;&lt;div&gt;Anyway, that’s all.  If it doesn’t work, don’t blame me.  That’s as dead simple as I know how to make it.&lt;/div&gt;" />
<link rel="canonical" href="http://localhost:4000/2016/08/09/using-pocketsphinx-within-python-code/" />
<meta property="og:url" content="http://localhost:4000/2016/08/09/using-pocketsphinx-within-python-code/" />
<meta property="og:site_name" content="nixing around" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2016-08-09T16:21:00-04:00" />
<script type="application/ld+json">
{"name":null,"description":"Here’s the source for what I’ve been working on. Looks like my installation records will have to be updated to account for a different installation source, and maybe a different version of the source code.Ok, here’s the process so far.  Install sphinxbase and pocketsphinx from GitHub - this means using the bleeding-edge versions, rather than the tried-and true alpha5 versions that I talked about in previous posts.  This just seems to work better.  Once this is all figured out, I’ll go back and clean those up.&lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;cd ~/toolsgit clone https://github.com/cmusphinx/sphinxbase.gitcd ./sphinxbase./autogen.sh./configuremakemake checkmake installcd ~/toolsgit clone https://github.com/cmusphinx/pocketsphinx.gitcd ./pocketsphinx./autogen.sh./configuremake clean allmake checksudo make install&lt;/pre&gt;Now look inside the pocketsphinx directory:&lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;cd ~/tools/pocketsphinx/swig/python/test&lt;/pre&gt;There’s a whole bunch of test scripts that walk you through the implementation of pocketsphinx in python.  It’s basically done for you.  Check the one called kws-test.py – that’s the one that will wait to hear a keyword, run a command when it does, then resume listening.  Perfect!I’m going to assume that you’ve already created your own voice model based on the other posts in this blog, and that you’ve got a directory dedicated to command and control experiments. If that’s not true, then just mess with the script without moving it.  Just make a backup.  The only effective difference is that the detection will be less accurate; for the purposes of this tutorial, ignore the rest of the code down to where I’ve pasted my copy of the python script.  The only thing you should change has to do with reading from the microphone rather than an audio file; change the script to match what I’ve got here.  You’re done now.  The rest of this tutorial is for those who have already created their own voice model.  See others of my posts for how to do that.&lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;# Open file to read the data# stream = open(os.path.join(datadir, “test-file.wav”), “rb”)# Alternatively you can read from microphoneimport pyaudio p = pyaudio.PyAudio()stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)stream.start_stream()&lt;/pre&gt;Ok.  For the rest of us, let’s get back to messing with this script.  While still in the test directory,&lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;mkdir ~/tools/cc_excp ./kws_test.py ~/tools/cc_ex/kws_test.pycd ~/tools/cc_ex/gedit kws_test.py&lt;/pre&gt;There’s a few changes to make in the python script.  Make sure the model directory has been adjusted.  Also, the script by default is checking in a .raw audio file for the keyword: uncomment and comment the relevant lines so the script uses pyaudio to record from the microphone.  The full text of my version of the script is below. Note that the keyphrase it’s looking for is the word ‘and’.  Pretty simple, and very likely to have been covered a lot in the voice training.Note also that there’s a weird quirk in the detection - you have to speak quickly.  I tried for a long time making long, sonorous ‘aaaannnnddd’ noises at my microphone, and it didn’t pick up.  Finally gave a short, staccato ‘and’ - it detected me right away.  Did it five more times, and it picked me up each time.  I don’t see a way to get around that - I think it’s built into the buffer, so it won’t even hear the whole thing otherwise.  Or maybe I just said ‘and’ in the training really fast each time, though I don’t think that’s likely. &lt;pre style=&quot;background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;&quot;&gt;#!/usr/bin/pythonimport sys, osfrom pocketsphinx.pocketsphinx import *from sphinxbase.sphinxbase import *modeldir = “~/tools/train-voice-data-pocketsphinx”# Create a decoder with certain modelconfig = Decoder.default_config()config.set_string(‘-hmm’, os.path.join(modeldir, ‘neo-en/en-us’))config.set_string(‘-dict’, os.path.join(modeldir, ‘neo-en/cmudict-en-us.dict’))config.set_string(‘-keyphrase’, ‘and’)config.set_float(‘-kws_threshold’, 1e+1)#config.set_string(‘-logfn’, ‘/dev/null’)# Open file to read the data# stream = open(os.path.join(datadir, “test-file.wav”), “rb”)# Alternatively you can read from microphoneimport pyaudio p = pyaudio.PyAudio()stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)stream.start_stream()# Process audio chunk by chunk. On keyphrase detected perform action and restart searchdecoder = Decoder(config)decoder.start_utt()while True: buf = stream.read(1024) if buf: decoder.process_raw(buf, False, False) else: break if decoder.hyp() != None: print ([(seg.word, seg.prob, seg.start_frame, seg.end_frame) for seg in decoder.seg()]) print (“Detected keyphrase, restarting search”) decoder.end_utt() decoder.start_utt()&lt;/pre&gt;&lt;div&gt;Anyway, that’s all.  If it doesn’t work, don’t blame me.  That’s as dead simple as I know how to make it.&lt;/div&gt;","author":{"@type":"Person","name":"umhau"},"@type":"BlogPosting","url":"http://localhost:4000/2016/08/09/using-pocketsphinx-within-python-code/","publisher":null,"image":null,"headline":"Using PocketSphinx within Python Code","dateModified":"2016-08-09T16:21:00-04:00","datePublished":"2016-08-09T16:21:00-04:00","sameAs":null,"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2016/08/09/using-pocketsphinx-within-python-code/"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" type="text/css" href="/assets/css/styles.css">
    <meta name="viewport" content="width=device-width">
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
    <script src="/js/infinite-jekyll.js"></script>

  </head>
  <body>
    <box class="wrapper">
      <header>
        <a href="http://localhost:4000"> <h1>*nixing around</h1> </a>
        <p>A programmer's journal of complicated projects.</p>
        <p class="view"><a href="">github</a> | <a href="http://localhost:4000/about">about</a> | <a href="http://localhost:4000/explore">explore</a></p>

        <p>testing</p>

      </header>
      <section>

      <div class="post">

    <header class="post-header">
        
    <h1 class="post-title">Using PocketSphinx within Python Code</h1>
    <p 
        class="post-meta">Aug 9, 2016 • <a  href="/2016/08/09/using-pocketsphinx-within-python-code/">permalink</a>
        <i>  • Linux • speech to text • Mint 17.3 • python • audio transcription • CMU Sphinx • offline-transcription</i> 
    </p>
    </header>

    <article class="post-content">
    <a href="https://sourceforge.net/p/cmusphinx/discussion/help/thread/b64f8037/" target="_blank">Here's</a> the source for what I've been working on. <br /><br />Looks like my installation records will have to be updated to account for a different installation source, and maybe a different version of the source code.<br /><br />Ok, here's the process so far. &nbsp;Install sphinxbase and pocketsphinx from GitHub - this means using the bleeding-edge versions, rather than the tried-and true alpha5 versions that I talked about in previous posts. &nbsp;This just seems to work better. &nbsp;Once this is all figured out, I'll go back and clean those up.<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="line-height: 19.6px;">cd ~/tools<br />git clone https://github.com/cmusphinx/sphinxbase.git<br />cd ./sphinxbase<br />./autogen.sh<br />./configure<br />make<br />make check<br />make install<br /><br />cd ~/tools<br />git clone https://github.com/cmusphinx/pocketsphinx.git<br />cd ./pocketsphinx<br />./autogen.sh<br />./configure<br />make clean all<br />make check<br />sudo make install</span></span></pre>Now look inside the pocketsphinx directory:<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="line-height: 19.6px;">cd ~/tools/pocketsphinx/swig/python/test</span></span></pre>There's a whole bunch of test scripts that walk you through the implementation of pocketsphinx in python. &nbsp;It's basically done for you. &nbsp;Check the one called kws-test.py -- that's the one that will wait to hear a keyword, run a command when it does, then resume listening. &nbsp;Perfect!<br /><br />I'm going to assume that you've already created your own voice model based on the other posts in this blog, and that you've got a directory dedicated to command and control experiments. <br /><br />If that's not true, then just mess with the script without moving it. &nbsp;Just make a backup. &nbsp;The only effective difference is that the detection will be less accurate; for the purposes of this tutorial, ignore the rest of the code down to where I've pasted my copy of the python script. &nbsp;The only thing you should change has to do with reading from the microphone rather than an audio file; change the script to match what I've got here. &nbsp;You're done now. &nbsp;The rest of this tutorial is for those who have already created their own voice model. &nbsp;See others of my posts for how to do that.<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="line-height: 19.6px;"># Open file to read the data<br /># stream = open(os.path.join(datadir, "test-file.wav"), "rb")<br /><br /># Alternatively you can read from microphone<br />import pyaudio<br /> <br />p = pyaudio.PyAudio()<br />stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)<br />stream.start_stream()</span></span></pre>Ok. &nbsp;For the rest of us, let's get back to messing with this script. &nbsp;While still in the test directory,<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="line-height: 19.6px;">mkdir ~/tools/cc_ex<br />cp ./kws_test.py ~/tools/cc_ex/kws_test.py<br />cd ~/tools/cc_ex/<br />gedit kws_test.py</span></span></pre>There's a few changes to make in the python script. &nbsp;Make sure the model directory has been adjusted. &nbsp;Also, the script by default is checking in a .raw audio file for the keyword: uncomment and comment the relevant lines so the script uses pyaudio to record from the microphone. &nbsp;The full text of my version of the script is below. <br /><br />Note that the keyphrase it's looking for is the word 'and'. &nbsp;Pretty simple, and very likely to have been covered a lot in the voice training.<br /><br />Note also that there's a weird quirk in the detection - you have to speak quickly. &nbsp;I tried for a long time making long, sonorous 'aaaannnnddd' noises at my microphone, and it didn't pick up. &nbsp;Finally gave a short, staccato 'and' - it detected me right away. &nbsp;Did it five more times, and it picked me up each time. &nbsp;I don't see a way to get around that - I think it's built into the buffer, so it won't even hear the whole thing otherwise. &nbsp;Or maybe I just said 'and' in the training really fast each time, though I don't think that's likely. <br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="line-height: 19.6px;">#!/usr/bin/python<br /><br />import sys, os<br />from pocketsphinx.pocketsphinx import *<br />from sphinxbase.sphinxbase import *<br /><br /><br />modeldir = "~/tools/train-voice-data-pocketsphinx"<br /><br /># Create a decoder with certain model<br />config = Decoder.default_config()<br />config.set_string('-hmm', os.path.join(modeldir, 'neo-en/en-us'))<br />config.set_string('-dict', os.path.join(modeldir, 'neo-en/cmudict-en-us.dict'))<br />config.set_string('-keyphrase', 'and')<br />config.set_float('-kws_threshold', 1e+1)<br />#config.set_string('-logfn', '/dev/null')<br /><br /><br /># Open file to read the data<br /># stream = open(os.path.join(datadir, "test-file.wav"), "rb")<br /><br /># Alternatively you can read from microphone<br />import pyaudio<br /> <br />p = pyaudio.PyAudio()<br />stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)<br />stream.start_stream()<br /><br /># Process audio chunk by chunk. On keyphrase detected perform action and restart search<br />decoder = Decoder(config)<br />decoder.start_utt()<br />while True:<br />    buf = stream.read(1024)<br />    if buf:<br />         decoder.process_raw(buf, False, False)<br />    else:<br />         break<br />    if decoder.hyp() != None:<br />        print ([(seg.word, seg.prob, seg.start_frame, seg.end_frame) for seg in decoder.seg()])<br />        print ("Detected keyphrase, restarting search")<br />        decoder.end_utt()<br />        decoder.start_utt()</span></span><br /></pre><div>Anyway, that's all. &nbsp;If it doesn't work, don't blame me. &nbsp;That's as dead simple as I know how to make it.</div><br />
    </article>

    <p class="extra-space"></p>
    <hr>
    <p class="extra-space"></p>

</div>





      </section>
      <footer>
        <p><small>Hosted on GitHub &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a> and <a href="https://github.com/umhau">umhau</a></small></p>
      </footer>
    </box>
    <script src="/assets/js/scale.fix.js"></script>


  



  </body>
</html>
