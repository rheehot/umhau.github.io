---
layout: post
title: Using PocketSphinx within Python Code
date: '2016-08-09T16:21:00.001-04:00'
author: umhau
tags:
- Linux
- speech to text
- Mint 17.3
- python
- audio transcription
- CMU Sphinx
- offline-transcription
categories: walkthroughs experiments
modified_time: '2016-11-23T14:45:17.879-05:00'
blogger_id: tag:blogger.com,1999:blog-2584289275272726799.post-5248558423995221514
blogger_orig_url: http://nixingaround.blogspot.com/2016/08/using-pocketsphinx-within-python-code.html
---

<a href="https://sourceforge.net/p/cmusphinx/discussion/help/thread/b64f8037/" target="_blank">Here's</a> the source for what I've been working on. <br /><br />Looks like my installation records will have to be updated to account for a different installation source, and maybe a different version of the source code.<br /><br />Ok, here's the process so far. &nbsp;Install sphinxbase and pocketsphinx from GitHub - this means using the bleeding-edge versions, rather than the tried-and true alpha5 versions that I talked about in previous posts. &nbsp;This just seems to work better. &nbsp;Once this is all figured out, I'll go back and clean those up.<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="line-height: 19.6px;">cd ~/tools<br />git clone https://github.com/cmusphinx/sphinxbase.git<br />cd ./sphinxbase<br />./autogen.sh<br />./configure<br />make<br />make check<br />make install<br /><br />cd ~/tools<br />git clone https://github.com/cmusphinx/pocketsphinx.git<br />cd ./pocketsphinx<br />./autogen.sh<br />./configure<br />make clean all<br />make check<br />sudo make install</span></span></pre>Now look inside the pocketsphinx directory:<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="line-height: 19.6px;">cd ~/tools/pocketsphinx/swig/python/test</span></span></pre>There's a whole bunch of test scripts that walk you through the implementation of pocketsphinx in python. &nbsp;It's basically done for you. &nbsp;Check the one called kws-test.py -- that's the one that will wait to hear a keyword, run a command when it does, then resume listening. &nbsp;Perfect!<br /><br />I'm going to assume that you've already created your own voice model based on the other posts in this blog, and that you've got a directory dedicated to command and control experiments. <br /><br />If that's not true, then just mess with the script without moving it. &nbsp;Just make a backup. &nbsp;The only effective difference is that the detection will be less accurate; for the purposes of this tutorial, ignore the rest of the code down to where I've pasted my copy of the python script. &nbsp;The only thing you should change has to do with reading from the microphone rather than an audio file; change the script to match what I've got here. &nbsp;You're done now. &nbsp;The rest of this tutorial is for those who have already created their own voice model. &nbsp;See others of my posts for how to do that.<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="line-height: 19.6px;"># Open file to read the data<br /># stream = open(os.path.join(datadir, "test-file.wav"), "rb")<br /><br /># Alternatively you can read from microphone<br />import pyaudio<br /> <br />p = pyaudio.PyAudio()<br />stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)<br />stream.start_stream()</span></span></pre>Ok. &nbsp;For the rest of us, let's get back to messing with this script. &nbsp;While still in the test directory,<br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="line-height: 19.6px;">mkdir ~/tools/cc_ex<br />cp ./kws_test.py ~/tools/cc_ex/kws_test.py<br />cd ~/tools/cc_ex/<br />gedit kws_test.py</span></span></pre>There's a few changes to make in the python script. &nbsp;Make sure the model directory has been adjusted. &nbsp;Also, the script by default is checking in a .raw audio file for the keyword: uncomment and comment the relevant lines so the script uses pyaudio to record from the microphone. &nbsp;The full text of my version of the script is below. <br /><br />Note that the keyphrase it's looking for is the word 'and'. &nbsp;Pretty simple, and very likely to have been covered a lot in the voice training.<br /><br />Note also that there's a weird quirk in the detection - you have to speak quickly. &nbsp;I tried for a long time making long, sonorous 'aaaannnnddd' noises at my microphone, and it didn't pick up. &nbsp;Finally gave a short, staccato 'and' - it detected me right away. &nbsp;Did it five more times, and it picked me up each time. &nbsp;I don't see a way to get around that - I think it's built into the buffer, so it won't even hear the whole thing otherwise. &nbsp;Or maybe I just said 'and' in the training really fast each time, though I don't think that's likely. <br /><pre style="background-color: #eff0f1; border: 0px; margin-bottom: 1em; max-height: 600px; overflow: auto; padding: 5px; width: auto; word-wrap: normal;"><span style="color: #333333;"><span style="line-height: 19.6px;">#!/usr/bin/python<br /><br />import sys, os<br />from pocketsphinx.pocketsphinx import *<br />from sphinxbase.sphinxbase import *<br /><br /><br />modeldir = "~/tools/train-voice-data-pocketsphinx"<br /><br /># Create a decoder with certain model<br />config = Decoder.default_config()<br />config.set_string('-hmm', os.path.join(modeldir, 'neo-en/en-us'))<br />config.set_string('-dict', os.path.join(modeldir, 'neo-en/cmudict-en-us.dict'))<br />config.set_string('-keyphrase', 'and')<br />config.set_float('-kws_threshold', 1e+1)<br />#config.set_string('-logfn', '/dev/null')<br /><br /><br /># Open file to read the data<br /># stream = open(os.path.join(datadir, "test-file.wav"), "rb")<br /><br /># Alternatively you can read from microphone<br />import pyaudio<br /> <br />p = pyaudio.PyAudio()<br />stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)<br />stream.start_stream()<br /><br /># Process audio chunk by chunk. On keyphrase detected perform action and restart search<br />decoder = Decoder(config)<br />decoder.start_utt()<br />while True:<br />    buf = stream.read(1024)<br />    if buf:<br />         decoder.process_raw(buf, False, False)<br />    else:<br />         break<br />    if decoder.hyp() != None:<br />        print ([(seg.word, seg.prob, seg.start_frame, seg.end_frame) for seg in decoder.seg()])<br />        print ("Detected keyphrase, restarting search")<br />        decoder.end_utt()<br />        decoder.start_utt()</span></span><br /></pre><div>Anyway, that's all. &nbsp;If it doesn't work, don't blame me. &nbsp;That's as dead simple as I know how to make it.</div><br />